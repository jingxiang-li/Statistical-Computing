%!TEX program = pdflatex
%# -*- coding: utf-8 -*-
%!TEX encoding = UTF-8 Unicode

\documentclass[12pt,oneside,a4paper]{article}

%% ------------------------------------------------------
%% load packages
\usepackage{geometry}
\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage[pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false,
 unicode=true]
 {hyperref}
\hypersetup{pdfstartview={XYZ null null 1}}
\usepackage{url}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{microtype}

\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage[retainorgcmds]{IEEEtrantools}

% \usepackage{algorithm}
% \usepackage{algorithmic}
% \renewcommand{\algorithmicrequire}{\textbf{Input:}} 
% \renewcommand{\algorithmicensure}{\textbf{Output:}} 
\usepackage[algoruled, vlined]{algorithm2e}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[mono=false]{libertine}
\usepackage[libertine]{newtxmath}
\linespread{1.1} 
% \usepackage[toc,eqno,enum,bib,lineno]{tabfigures}

\usepackage{graphics}
\usepackage{graphicx}
\usepackage[figure]{hypcap}
\usepackage[hypcap]{caption}
\usepackage{tikz}
\usepackage{tikz-cd}
%\usepackage{grffile} 
%\usepackage{float} 
\usepackage{pdfpages}
\usepackage{pdflscape}
\usepackage{needspace}

\usepackage{multirow}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{dcolumn}
\usepackage{tabu}

\usepackage{verbatim}

\usepackage{etoolbox}
\BeforeBeginEnvironment{knitrout}{
    \begin{tabu} to \textwidth {XcX}
    \toprule[.7pt]
    & R Code Chunk & \\
    \bottomrule[.7pt]
    \end{tabu}
    \vspace*{-.5\baselineskip}
}
\AfterEndEnvironment{knitrout}{
    \vspace*{-.5\baselineskip}
    \noindent\rule{\textwidth}{.7pt}
}

%% Class, Exam, Date, etc.
\newcommand{\class}{STAT 5701: Statistical Computing}
\newcommand{\term}{Fall 2015}
\newcommand{\examnum}{Homework 1}
\newcommand{\hmwkTitle}{\class \\[1ex] \examnum}
\newcommand{\hmwkAuthorName}{Jingxiang Li}

\title{\hmwkTitle}
\author{\hmwkAuthorName}

\usepackage{fancyhdr}
\usepackage{extramarks}
\lhead{\hmwkAuthorName}
\chead{}
\rhead{\hmwkTitle}
\cfoot{\thepage}

\newcounter{problemCounter}
\newcounter{subproblemCounter}
\renewcommand{\thesubproblemCounter}{\alph{subproblemCounter}}
\newcommand{\problem}[0] {
    \clearpage
    \stepcounter{problemCounter}
    \setcounter{subproblemCounter}{0}
}

\newcommand{\subproblem}[0] {
    \stepcounter{subproblemCounter}
    \Needspace*{15\baselineskip}
    \vspace{1.8\baselineskip}
    \noindent{\textbf{\large{Problem \theproblemCounter.\hspace{1pt}\thesubproblemCounter}}}
    \vspace{\baselineskip}
    \newline
}

\newcommand{\solution} {
    \vspace{15pt}
    \noindent\ignorespaces\textbf{\large Solution}\par
}
\setlength\parindent{0pt}

%% some math shortcuts
\newcommand{\m}[1]{\texttt{{#1}}}
\newcommand{\E}[0]{\mathrm{E}}
\newcommand{\Var}[0]{\mathrm{Var}}
\newcommand{\sd}[0]{\mathrm{sd}}
\newcommand{\Cov}[0]{\mathrm{Cov}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
<<include=FALSE>>=
opts_chunk$set(fig.path='figure/', fig.align='center', fig.show='hold', tidy=FALSE, tidy.opts=list(keep.blank.line=TRUE, width.cutoff=50), warning=FALSE, error=FALSE, message=FALSE, echo=TRUE, crop = TRUE, cache=TRUE, size="footnotesize")
#, sanitize=TRUE, dev="tikz")
options(replace.assign=TRUE, width=90)
knit_theme$set("edit-eclipse")
knit_hooks$set(document = function(x) {
    sub('\\usepackage[]{color}', '\\usepackage[]{xcolor}', x, fixed = TRUE) 
}, crop = hook_pdfcrop)
@
\maketitle

\problem
\subproblem
\begin{algorithm}[H]
\DontPrintSemicolon
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetKwData{X}{x}\SetKwData{U}{u}\SetKwData{Sample}{sample}\SetKwData{Size}{i}
\SetKwData{N}{n}\SetKwData{F}{$f$}
\Input{Sample size \N}
\Output{A vector consists of \N i.i.d. observations from density function \F}
\Begin {
    $\Sample [\N ] = \{ 0 \}$, $\Size = 0$\;
    \While{$\Size \neq \N$}{
        draw $\X$ from $\mathrm{Unif}(-1, 1)$\;
        draw $\U$ from $\mathrm{Unif}(0, 1)$\;
        \If{$\U < \frac{4}{3} \F(\X)$} {$\Size = \Size + 1$\;
        $\Sample [\Size ] = \X$}
    }
}
\caption{Draw Sample Given Density Function $f$}
\end{algorithm}

\subproblem
<<p1b>>=
f <- function (x) {
#     Calculate density value
#     Input:
#         x: numeric value
#     Output:
#         density value
    ifelse(x > -1 && x < 1, 
           3 / 4 * (1 - x^2), 
           0)
}

rquad <- function (n) {
#     Draw sample from f by rejection sampling
#     Input:
#         n: sample size
#     Output:
#         x.list: n i.i.d. observations from f
#         k.list: number of iterations used to produce each observation
    x.list <- numeric(length = n)
    k.list <- numeric(length = n)
    i <- 0
    iter <- 0
    while (i != n) {
        iter <- iter + 1
        x <- runif(n = 1, min = -1, max = 1)
        u <- runif(n = 1)
        if (u < 4 / 3 * f(x)) {
            i <- i + 1
            x.list[i] <- x
            k.list[i] <- iter
            iter <- 0
        }
    }
    return (list(x.list = x.list, k.list = k.list))
}
@

\subproblem
<<p1c, fig.width=6, fig.height=6, out.width='.5\\linewidth'>>=
n <- 1000
mySample <- rquad(n)
hist(mySample$x.list)
mean(mySample$k.list)
@

On average each realization requires \Sexpr{mean(mySample$k.list)} iterations.

\problem
\subproblem
<<p2a>>=
box.muller.trans <- function (mu, sigma) {
#     Box-Muller's method to generate N(mu, sigma) sample
#     Input:
#         mu: mean
#         sigma: standard deviation
#     Output:
#         a vector consists 2 i.i.d. observations from N(mu, sigma)
    u <- runif(n = 2)
    z <- numeric(length = 2)
    z[1] <- sqrt(-2 * log(u[1])) * cos(2 * pi * u[2])
    z[2] <- sqrt(-2 * log(u[1])) * sin(2 * pi * u[2])
    return (z * sigma + mu)
}

myrtnorm <- function (n, mu, sigma, a, b) {
#     Draw sample from truncated normal distribution by rejection sampling
#     Z ~ (X | a < X < b) where X ~ N(mu, sigma)
#     Input:
#         n: sample size
#         mu: mean
#         sigma: standard deviation
#         a: lower bound for the truncated dist
#         b: upper bound for the truncated dist
#     Output:
#         a vector of n i.i.d. observations
    t.list <- numeric(n)
    i <- 0
    while (i < n) {
        z.vec <- box.muller.trans(mu, sigma)
        for (z in z.vec) {
            if (a < z && z < b) {
                i <- i + 1
                t.list[i] <- z
            }
        }
    }
    return (t.list)
}
@

\subproblem
$$\frac{1}{\Phi(\frac{b - \mu}{\sigma}) - \Phi(\frac{a - \mu}{\sigma})}$$

\subproblem
<<p2c, fig.width=6, fig.height=6, out.width='.5\\linewidth'>>=
n <- 500
mu <- 0
sigma <- 1
a <- -1
b <- 1

iter.num <- 1 / (pnorm(q = b, mean = mu, sd = sigma) - 
                     pnorm(q = a, mean = mu, sd = sigma))
iter.num

mySample <- myrtnorm(n = n, mu = mu, sigma = sigma, 
                     a = a, b = b)
hist(mySample)
@

\problem
\subproblem
<<p3a>>=
exp.quantile <- function (p, mu) {
#     Quantile function for Exp(mu)
#     Input: 
#         p: probability
#         mu: mean
#     Output:
#         quantile value for p
    return (- log(1 - p) * mu)
}
myrexp <- function (n, mu) {
#     Draw sample from Exp(mu)
#     Input: 
#         n: sample size
#         mu: mean
#     Output:
#         a vector consists of n i.i.d. observations from Exp(mu)
    return (exp.quantile(runif(n), mu))
}
@

\subproblem
<<p3b, fig.width=6, fig.height=6, out.width='.5\\linewidth'>>=
adam.qqplot <- function (x.list, quant.func, ...) {
#     Draw qqplot (modified from Adam's code)
#     Input:
#         x.list: target sample
#         quant.func: quantile function for the target distribution
#         ...: parameters pass to the quant.func()
#     Output:
#         plot is generated
    n <- length(x.list)
    probs <- ppoints(n)
    plot(quant.func(probs, ...), quantile(x.list, probs), 
         xlab="Expected percentile", ylab="Data percentile", 
         main = "Q-Q Plot")
    abline(0, 1)    
}
n <- 1000
mu <- 2
exp.list <- myrexp(n = n, mu = mu)
adam.qqplot(x.list = exp.list, quant.func = exp.quantile, mu = mu)
@

\subproblem
<<p3c>>=
run.exp.sim <- function (n, mu, reps) {
#     Simulation for sample mean (Y_bar) of i.i.d. Exp(mu) random observations
#     Input:
#         n: sample size
#         mu: mean of the Exp dist
#         reps: replication times
#     Output:
#         return a vector of Y_bar realizations
#         draw qq plot to compare the dist of Y_bar and Normal dist
    ybar.list <- numeric(reps)
    for (i in 1 : reps)
        ybar.list[i] <- mean(myrexp(n, mu))
    adam.qqplot(x.list = ybar.list, 
                quant.func = qnorm, 
                mean = mu, sd = mu / sqrt(n))
    return (ybar.list)
}
@

\subproblem
<<p3d, fig.width=6, fig.height=6, out.width='.5\\linewidth'>>=
my.sim <- run.exp.sim(n = 30, mu = 3.4, reps = 10000)
@

From the Q-Q plot we could see the sample mean shifts away from the line significantly in the tail parts, hence it's not that appropriate to apply normal approximation for inference. The sample size is not large enough.

\problem
\subproblem
<<p4a>>=
mymvrnorm <- function(n, mu, Sigma) {
#     Generate n i.i.d. observations from N(mu, Sigma)
#     Input:
#         n: sample size
#         mu: mean vector
#         Sigma: variance matrix
#     Output:
#         sample.matrix (n x d): n i.i.d. observations from N(mu, Sigma)
    sigma.eig <- eigen(Sigma)
    sigma.sqrt <- sigma.eig$vectors %*% 
        diag(sqrt(sigma.eig$values)) %*% 
        t(sigma.eig$vectors)
    d <- dim(Sigma)[1]
    sample.matrix <- matrix(data = 0, nrow = n, ncol = d)
    for (i in 1 : d)
        sample.matrix[, i] <- myrtnorm(n = n, mu = 0, sigma = 1, 
                                     a = -Inf, b = Inf)    
    sample.matrix <- sample.matrix %*% sigma.sqrt
    sample.matrix <- sample.matrix + matrix(rep(mu, n), nrow = n, byrow = TRUE)
    return (sample.matrix)
}
@

\subproblem
\renewcommand{\theenumi}{\roman{enumi}}
\begin{enumerate}
    \item $$\mu(\bar{X}) = \mu ~~~~~~~~~ \Var(\bar{X}) = \frac{\sigma^2}{n}$$
    \item $$\mu(\bar{H}) = \mu ~~~~~~~~~ \Var(\bar{H}) = \frac{\sigma^2}{n} + \frac{\sum_{k = 1}^{n - 1}\sum_{|i - j| = k}{\sigma^{2}\cdot 0.7^{|i - j|}}}{n^2}$$
    \item $\bar{H}$ is worse than $\bar{X}$
\end{enumerate}

\subproblem
<<p4c>>=
n <- 50000
d <- 10
mu <- rep(68, d)
sigma <- 3
Sigma <- matrix(data = 0, nrow = d, ncol = d)
for (i in 1 : d) {
    for (j in 1 : d) {
        Sigma[i, j] = sigma^2 * 0.7^abs(i - j)
    }
}
sim.h <- mymvrnorm(n, mu, Sigma)
sim.hbar <- apply(sim.h, 1, mean)
sim.x <- mymvrnorm(n, mu, diag(rep(sigma^2, d)))
sim.xbar <- apply(sim.x, 1, mean)

mean(sim.hbar)
mean(sim.xbar)
var(sim.hbar)
var(sim.xbar)
@

Simulation result shows that $\mu(\bar{X})$ and $\mu(\bar{H})$ are very close to $\mu$, and $\Var(\bar{H})$ is significantly larger than $\Var(\bar{X})$, which supports my prevoius argument.


\end{document}