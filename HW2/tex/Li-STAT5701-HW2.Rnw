%!TEX program = pdflatex
%# -*- coding: utf-8 -*-
%!TEX encoding = UTF-8 Unicode

\documentclass[12pt,oneside,a4paper]{article}

%% ------------------------------------------------------
%% load packages
\usepackage{geometry}
\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage[pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false,
 unicode=true]
 {hyperref}
\hypersetup{pdfstartview={XYZ null null 1}}
\usepackage{url}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{microtype}

\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage[retainorgcmds]{IEEEtrantools}

% \usepackage{algorithm}
% \usepackage{algorithmic}
% \renewcommand{\algorithmicrequire}{\textbf{Input:}} 
% \renewcommand{\algorithmicensure}{\textbf{Output:}} 
\usepackage[algoruled, vlined]{algorithm2e}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[mono=false]{libertine}
\usepackage[libertine]{newtxmath}
\linespread{1.1} 
% \usepackage[toc,eqno,enum,bib,lineno]{tabfigures}

\usepackage{graphics}
\usepackage{graphicx}
\usepackage[figure]{hypcap}
\usepackage[hypcap]{caption}
\usepackage{tikz}
\usepackage{tikz-cd}
%\usepackage{grffile} 
%\usepackage{float} 
\usepackage{pdfpages}
\usepackage{pdflscape}
\usepackage{needspace}

\usepackage{multirow}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{dcolumn}
\usepackage{tabu}

\usepackage{verbatim}

\usepackage{etoolbox}
\BeforeBeginEnvironment{knitrout}{
    \begin{tabu} to \textwidth {XcX}
    \toprule[.7pt]
    & R Code Chunk & \\
    \bottomrule[.7pt]
    \end{tabu}
    \vspace*{-.5\baselineskip}
}
\AfterEndEnvironment{knitrout}{
    \vspace*{-.5\baselineskip}
    \noindent\rule{\textwidth}{.7pt}
}

%% Class, Exam, Date, etc.
\newcommand{\class}{STAT 5701: Statistical Computing}
\newcommand{\term}{Fall 2015}
\newcommand{\examnum}{Homework 2}
\newcommand{\hmwkTitle}{\class \\[1ex] \examnum}
\newcommand{\hmwkAuthorName}{Jingxiang Li}

\title{\hmwkTitle}
\author{\hmwkAuthorName}

\usepackage{fancyhdr}
\usepackage{extramarks}
\lhead{\hmwkAuthorName}
\chead{}
\rhead{\hmwkTitle}
\cfoot{\thepage}

\newcounter{problemCounter}
\newcounter{subproblemCounter}
\renewcommand{\thesubproblemCounter}{\alph{subproblemCounter}}
\newcommand{\problem}[0] {
    \clearpage
    \stepcounter{problemCounter}
    \setcounter{subproblemCounter}{0}
}

\newcommand{\subproblem}[0] {
    \stepcounter{subproblemCounter}
    \Needspace*{5\baselineskip}
    \vspace{1.8\baselineskip}
    \noindent{\textbf{\large{Problem \theproblemCounter.\hspace{1pt}\thesubproblemCounter}}}
    \vspace{\baselineskip}
    \newline
}

\newcommand{\solution} {
    \vspace{15pt}
    \noindent\ignorespaces\textbf{\large Solution}\par
}
\setlength\parindent{0pt}

%% some math shortcuts
\newcommand{\m}[1]{\texttt{{#1}}}
\newcommand{\E}[0]{\mathrm{E}}
\newcommand{\Var}[0]{\mathrm{Var}}
\newcommand{\sd}[0]{\mathrm{sd}}
\newcommand{\Cov}[0]{\mathrm{Cov}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
<<include=FALSE>>=
opts_chunk$set(fig.path='figure/', fig.align='center', fig.show='hold', tidy=FALSE, tidy.opts=list(keep.blank.line=TRUE, width.cutoff=50), warning=FALSE, error=FALSE, message=FALSE, echo=TRUE, crop = TRUE, cache=TRUE, size="footnotesize")
#, sanitize=TRUE, dev="tikz")
options(replace.assign=TRUE, width=90)
knit_theme$set("edit-eclipse")
knit_hooks$set(document = function(x) {
    sub('\\usepackage[]{color}', '\\usepackage[]{xcolor}', x, fixed = TRUE) 
}, crop = hook_pdfcrop)
@
\maketitle

<<head, echo = FALSE>>=
require(MASS)
set.seed(5701)
@

\problem
\subproblem
In this problem we first make a R function called \m{confint\_sigma\_sq}, which directly implements the confidence interval formula given by the problem. The function \m{confint\_sigma\_sq} takes two parameters: \m{x} and \m{alpha}, where \m{x} is a vector of observations and $1 - \m{alpha}$ is the confidence level for the $\sigma ^2$. 

Then, we make another R function called \m{sim\_confint\_sigma\_sq\_norm}, which simulates the confidence interval of $\sigma^2$ for i.i.d. normal random observations. There will be in total $\m{reps}$ replications in the simulation study. For each iteration, we first draw \m{n} random realizations from a normal distribution with mean \m{mu} and standard deviation \m{sigma}. Then we will estimate the $1 - \m{alpha}$ confidence interval of the $\sigma^2$ based on this realization, and record if the true $\sigma^2$ is within the confidence interval using $\{0, 1\}$ indicators. At the end of the simulation we will perform a proportional test for those indicators, and derive the \m{score\_conf} level confidence interval for the true proportion of 1's among all of them.

After building these two functions, we will do simulation according the the problem.
\newline

<<p1.a>>=
#' compute the confidence interval of sigma^2 given i.i.d. observations
#'
#' @param x vector of i.i.d. observations
#' @param alph this is 1 - confidence level
#'
#' @return a vector (left, right), (1 - alpha) confidence interval of sigma^2
#' @export
confint_sigma_sq = function(x, alpha = 0.05) {
    n = length(x)
    var_sample = var(x)
    left = (n - 1) * var_sample / qchisq(1 - alpha / 2, df = n - 1)
    right = (n - 1) * var_sample / qchisq(alpha / 2, df = n - 1)
    c(left, right)
}

#' simulate the confidence interval of sigma^2 for i.i.d. normal random
#' observations
#'
#' @param reps number of replications for the simulation study
#' @param n sample size of normal realization
#' @param mu true mean of the normal distribution
#' @param sigma true standard deviation of the normal distribution
#' @param alpha alpha level used for constructing confidence interval of sigma^2
#' @param score_conf confidence level for constructing the confidence interval
#'   of the coverage probability
#'
#' @return a vector (left, right), score_conf level confidence interval for the
#'   coverage probability
#' @export
sim_confint_sigma_sq_norm = function(reps, n, mu, sigma, alpha, score_conf) {
    x_sim = rnorm(n = n * reps, mean = mu, sd = sigma)
    x_sim = matrix(x_sim, nrow = reps, ncol = n)
    int_sim = apply(x_sim, 1, confint_sigma_sq, alpha = alpha)
    indicator_sim = apply(int_sim, 2, function(x) {
        x[1] < sigma ^ 2 && x[2] > sigma ^ 2
    })
    test_result = prop.test(
        sum(indicator_sim), n = reps,
        p = 1 - alpha, conf.level = score_conf
    )
    test_result$conf.int
}

reps = 10000
n = 10
mu = 68
sigma = 3
alpha = 0.05
score_conf = 0.99
sim_confint_sigma_sq_norm(reps, n, mu, sigma, alpha, score_conf)
@
Here we could see the simulated 99\% confidence interval for the coverage probability is $(0.9399294, 0.9516740)$. Note that the target coverage probability 0.95 is inside the confidence interval, and the lower and upper bound for the interval are both very close to 0.95, which suggests that under this scenario, the formula gives a good confidence interval for $\sigma^2$.  

\subproblem
In this problem we will still use the function \m{confint\_sigma\_sq} to estimate the confidence interval. But we create another simulation function \m{sim\_confint\_sigma\_sq\_exp} to simulate the confidence interval of $\sigma^2$ for i.i.d. $\mathrm{Exp}(1)$ random observations. Note that this function is very close to function \m{sim\_confint\_sigma\_sq\_norm}, the only difference is that we draw sample from $\mathrm{Exp}(1)$ rather than a normal distribution.
\newline

<<p1.b>>=
#' simulate the confidence interval of sigma^2 for i.i.d. Exp(1) random
#' observations
#'
#' @param number of replications for the simulation study
#' @param n sample size of normal realization
#' @param alpha alpha level used for constructing confidence interval of sigma^2
#' @param score_conf confidence level for constructing the confidence interval
#'   of the coverage probability
#'
#' @return a vector (left, right), score_conf level confidence interval for the
#'   coverage probability
#' @export
sim_confint_sigma_sq_exp = function(reps, n, alpha, score_conf) {
    x_sim = rexp(n = n * reps)
    x_sim = matrix(x_sim, nrow = reps, ncol = n)
    int_sim = apply(x_sim, 1, confint_sigma_sq, alpha = alpha)
    indicator_sim = apply(int_sim, 2, function(x) {
        x[1] < 1 && x[2] > 1
    })
    test_result = prop.test(
        sum(indicator_sim), n = reps,
        p = 1 - alpha, conf.level = score_conf
    )
    test_result$conf.int
}

reps = 10000
n_vec = c(10, 50, 500)
alpha_vec = c(0.01, 0.05)
score_conf = 0.99
result = matrix(0, length(n_vec) * length(alpha_vec), 4)
colnames(result) = c("n", "alpha", "left", "right")
k = 1
for (n in n_vec)
    for (alpha in alpha_vec) {
        result[k, 1] = n
        result[k, 2] = alpha
        result[k, c(3, 4)] = sim_confint_sigma_sq_exp(reps, n, alpha, score_conf)
        k = k + 1
    }
result
@
Here we could see the resulting confidence interval for the coverage probability is far away from $1 - \alpha$, which suggests that this is not a proper way to construct confidence interval of $\sigma^2$ for i.i.d. exponential random variables.

\subproblem
In this problem we will still use the function \m{confint\_sigma\_sq} to estimate the confidence interval. But we create another simulation function \m{sim\_confint\_sigma\_sq\_multinorm} to simulate the confidence interval of $\sigma^2$ for multivariate normal random observations. Note that this function is very close to function \m{sim\_confint\_sigma\_sq\_norm}, the only difference is that we draw sample from a multivariate normal distribtuion rather than a normal distribution.
\newline

<<p1.c>>=
#' simulate the confidence interval of sigma^2 for multivariate normal random
#' observations, with mean = rep(mu, n), covariance matrix var_mat, where
#' var_mat[i, j] = sigma ^ 2 * rho ^ abs(i - j)
#'
#' @param reps number of replications for the simulation study
#' @param n sample size of normal realization
#' @param mu true mean of the normal distribution
#' @param sigma true marginal standard deviation of the normal distribution
#' @param rho decay parameter used for constructing the covariace matrix
#' @param alpha alpha level used for constructing confidence interval of sigma^2
#' @param score_conf confidence level for constructing the confidence interval
#'   of the coverage probability
#'
#' @return a vector (left, right), score_conf level confidence interval for the
#'   coverage probability
#' @export
sim_confint_sigma_sq_multinorm = function(reps, n, mu, sigma, rho, alpha, score_conf) {
    mean_vec = rep(mu, n)
    var_mat = matrix(0, n, n)
    for (i in 1:n)
        for (j in 1:n) {
            var_mat[i, j] = sigma ^ 2 * rho ^ abs(i - j)
        }
    x_sim = mvrnorm(reps, mean_vec, var_mat)
    int_sim = apply(x_sim, 1, confint_sigma_sq, alpha = alpha)
    indicator_sim = apply(int_sim, 2, function(x) {
        x[1] < sigma ^ 2 && x[2] > sigma ^ 2
    })
    test_result = prop.test(
        sum(indicator_sim), n = reps,
        p = 1 - alpha, conf.level = score_conf
    )
    test_result$conf.int
}

reps = 10000
n_vec = c(10, 50, 500)
alpha_vec = c(0.01, 0.05)
score_conf = 0.99
mu = 68
sigma = 3
rho = 0.7
result = matrix(0, length(n_vec) * length(alpha_vec), 4)
colnames(result) = c("n", "alpha", "left", "right")
k = 1
for (n in n_vec)
    for (alpha in alpha_vec) {
        result[k, 1] = n
        result[k, 2] = alpha
        result[k, c(3, 4)] =
            sim_confint_sigma_sq_multinorm(reps, n, mu, sigma, rho, alpha, score_conf)
        k = k + 1
    }
result
@
Here we could see the resulting confidence interval for the coverage probability is far away from $1 - \alpha$, which suggests that this is not a proper way to construct confidence interval of $\sigma^2$ for dependent normal random variables.

\problem
\subproblem
In this problem we first make a function called \m{sim\_pval\_ttest}, which simulates p-values from a t-test scenario where two samples are drawn from normal distribution. Then, we make a function called \m{calc\_power} to calculate power of the t-test given a vector of simulated p-values.
\newline

<<p2.a, fig.width=6, fig.height=6, out.width='.5\\linewidth'>>=
#' simulate p-values from a t-test scenario where two samples are drawn from 
#' normal distribution
#'
#' @param reps number of replications for this simulation
#' @param n1 sample size of sample #1
#' @param n2 sample size of sample #2
#' @param mu1 mean value of sample #1
#' @param mu2 mean value of sample #2
#' @param sigma1 standard deviation of sample #1
#' @param sigma2 standard deviation of sample #2
#'
#' @return a vector of p-values calculated from a series of t-tests
sim_pval_ttest = function(reps, n1, n2, mu1, mu2, sigma1, sigma2) {
    x1 = rnorm(reps * n1, mu1, sigma1)
    x1 = matrix(x1, reps, n1)
    x2 = rnorm(reps * n2, mu2, sigma2)
    x2 = matrix(x2, reps, n2)
    p_values = numeric(reps)
    for (r in 1:reps) {
        test_result = t.test(x1[r,], x2[r,], var.equal = TRUE)
        p_values[r] = test_result$p.value
    }
    p_values
}

#' calculate the power of a test given a simulated p-value vector
#'
#' @param vector of simulated p-value based on the test 
#' @param significance level to determine the rejection region
#'
#' @return the power of the test
calc_power = function(pvals, alpha) {
    sum(pvals > (1 - alpha / 2) | pvals < (alpha / 2)) / length(pvals)
}

n1 = n2 = 50
mu1 = mu2 = 68
sigma1 = sigma2 = 3
reps = 1000

p_values = sim_pval_ttest(reps, n1, n2, mu1, mu2, sigma1, sigma2)
hist(p_values)
@

From the histogram of the p-values, it seems that the actual distribution of the random p-value is Unif$(0, 1)$. We will prove it in the next line.

\proof
Note that if $u \sim \mathrm{Unif}(0, 1)$, $\mathrm{P}(u < \alpha) = \alpha, ~\forall \alpha \in [0, 1]$. 

Let $p$ be the p-value, under $H_{0}$ we have
\begin{equation*}
\begin{aligned}
    & \mathrm{P}(p < \alpha | H_{0})\\
    =~ & \mathrm{P}(t > T_{1 - \alpha / 2} ~ \mathrm{or} ~ t < T_{\alpha / 2}| H_{0})\\
    =~ & \mathrm{P}(t > T_{1 - \alpha / 2}| H_{0}) + \mathrm{P}(t < T_{\alpha / 2}| H_{0})\\
    =~ & \alpha / 2 + \alpha / 2 \\
    =~ & \alpha
\end{aligned}
\end{equation*}
i.e., $\forall \alpha \in [0, 1]$ $\mathrm{P}(p < \alpha| H_{0}) = \alpha$, which implies that p-value has a uniform distribution under $H_{0}$. Q.E.D.

\subproblem
In this problem we first specify some potential values for $\mu_2$ and do simulation to get the approximate power for each corresponding $\mu_2$ value. Then we will extract those values that satisfies the condition specified by the problem.
\newline

<<p2.b>>=
n1 = n2 = 50
mu1 = 68
sigma1 = sigma2 = 3
alpha = 0.05
reps = 1000

length_mu2 = 5
mu2_vec = seq(from = mu1, by = 1, length.out = length_mu2)
power_result = numeric(length_mu2)
for (i in 1:length_mu2) {
    p_values = sim_pval_ttest(reps, n1, n2, mu1, mu2_vec[i], sigma1, sigma2)
    power_result[i] = calc_power(p_values, alpha)
}
power_result[power_result < 1]
mu2_vec[power_result < 1]
@

The sequence of values for $\mu_2$ we select is $68, 69, 70, 71$, and the corresponding power for these values are $0.057, 0.249, 0.850, 0.997$.

\subproblem
In this problem we first specify some potential values for sample size \m{n} and do simulation to get the approximate power for each corresponding \m{n} value. Then we will extract those values that satisfies the condition specified by the problem.
\newline

<<2.c>>=
mu1 = 68
mu2 = 68.5
sigma1 = sigma2 = 3
alpha = 0.05
reps = 1000

length_n = 10
n_vec = seq(from = 1050, by = 20, length.out = length_n)
power_result = numeric(length_n)
for (i in 1:length_n) {
    p_values = sim_pval_ttest(reps, n_vec[i], n_vec[i], mu1, mu2, sigma1, sigma2)
    power_result[i] = calc_power(p_values, alpha)
}

power_result[which.min(abs(power_result - 0.95))]
n_vec[which.min(abs(power_result - 0.95))]
@

The sample size we find is 1090, with corresponding power 0.951.

\subproblem
In this problem use function \m{sim\_pval\_ttest} to simlulate the p-values for each scenario, and then draw QQ-plot and histogram to see that pattern of those p-values.
\newline

<<2.d.i, fig.width=8, fig.height=4, out.width='.95\\linewidth'>>=
#' Draw qqplot (modified from Adam's code)
#'
#' @param x.list target sample
#' @param quant.func quantile function for the target distribution
#' @param ... parameters to be passed to the quant.func()
#'
#' @return no return value
adam.qqplot = function (x.list, quant.func, ...) {
    n <- length(x.list)
    probs <- ppoints(n)
    plot(
        quant.func(probs, ...), quantile(x.list, probs),
        xlab = "Expected percentile", ylab = "Data percentile",
        main = "Q-Q Plot"
    )
    abline(0, 1)
}

n1 = n2 = 100
mu1 = mu2 = 68
sigma1 = 3
sigma2 = 6
reps = 1000

p_values = sim_pval_ttest(reps, n1, n2, mu1, mu2, sigma1, sigma2)
par(mfrow = c(1, 2))
adam.qqplot(p_values, qunif)
hist(p_values)
quantile(p_values, c(0.01, 0.05))
@

In this scenario, $n1$ is equal to $n2$. The QQ-plot shows that the distribution of simulated p-values is perfectly uniform, and the true 0.01, 0.05 data quantiles are very close to 0.01 and 0.05, suggesting that with equal sample size, the difference in variance is not a problem.\newline

<<p2.d.ii, fig.width=8, fig.height=4, out.width='.95\\linewidth'>>=
n1 = 20
n2 = 100
mu1 = mu2 = 68
sigma1 = 3
sigma2 = 6
reps = 1000

p_values = sim_pval_ttest(reps, n1, n2, mu1, mu2, sigma1, sigma2)
par(mfrow = c(1, 2))
adam.qqplot(p_values, qunif)
hist(p_values)
quantile(p_values, c(0.01, 0.05))
@

In this scenario $n2 > n1$, which means sample with lower variance has smaller sample size, and sample with higher variance has larger sample size. The QQ-plot shows that the distribution is not uniform, it's a left-skewed distribution. The true 0.01, 0.05 data quantiles are significantly larger than 0.01 and 0.05, which suggests that using 0.01 and 0.05 as cut values is too conservative. \newline

<<p2.d.iii, fig.width=8, fig.height=4, out.width='.95\\linewidth'>>=
n1 = 100
n2 = 20
mu1 = mu2 = 68
sigma1 = 3
sigma2 = 6
reps = 1000

p_values = sim_pval_ttest(reps, n1, n2, mu1, mu2, sigma1, sigma2)
par(mfrow = c(1, 2))
adam.qqplot(p_values, qunif)
hist(p_values)
quantile(p_values, c(0.01, 0.05))
@

In this scenario $n2 < n1$, which means sample with lower variance has larger sample size, and sample with higher variance has smaller sample size. The QQ-plot shows that the distribution is not uniform, it's a right-skewed distribution. The true 0.01, 0.05 data quantiles are significantly smaller than 0.01 and 0.05, which suggests that using 0.01 and 0.05 as cut values failed to protect the corresponding type I error.

\subproblem
In this problem we first create a function called \m{sim\_pval\_ttest\_multinorm} to simulate a vector of p-values from the t-test according to the problem. and then we will draw QQ-plot and histogram to show the pattern of the p-values.
\newline

<<p2.e, fig.width=8, fig.height=4, out.width='.95\\linewidth'>>=
#' simulate p-values in a t-test scenario where data are generated from a 
#' multivariate normal distribution
#'
#' @param reps number of replications in the simulation study
#' @param n sample size for each group
#' @param mu1 marginal mean for group 1
#' @param mu2 marginal mean for group 2
#' @param sigma marginal standard deviation for both groups
#' @param rho decay parameter for the covariance between two grouops
#'
#' @return a vector of simulated p-values
sim_pval_ttest_multinorm = function(reps, n, mu1, mu2, sigma, rho) {
    mu_vec = c(mu1, mu2)
    var_mat = matrix(0, 2, 2)
    var_mat[1, 1] = var_mat[2, 2] = sigma ^ 2
    var_mat[1, 2] = var_mat[2, 1] = sigma ^ 2 * rho
    p_values = numeric(reps)
    for (r in 1:reps) {
        data_xy = mvrnorm(n, mu_vec, var_mat)
        test_result = t.test(data_xy[, 1], data_xy[, 2], var.equal = TRUE)
        p_values[r] = test_result$p.value
    }
    p_values
}

n = 20
mu1 = mu2 = 68
sigma = 3
rho = 0.01
reps = 1000

p_values = sim_pval_ttest_multinorm(reps, n, mu1, mu2, sigma, rho)
par(mfrow = c(1, 2))
adam.qqplot(p_values, qunif)
hist(p_values)
quantile(p_values, c(0.01, 0.05))
@

In this case $\rho = 0.01$, which suggests very low correlation among random variables. Then the QQ-plot shows that the distribution of resulting p-values is very close to uniform, and the true 0.01, 0.05 data quantiles are very close to 0.01 and 0.05, suggesting that low correlation among observations is not a problem for t-test. \newline

<<p2.e.ii, fig.width=8, fig.height=4, out.width='.95\\linewidth'>>=
n = 20
mu1 = mu2 = 68
sigma = 3
rho = 0.1
reps = 1000

p_values = sim_pval_ttest_multinorm(reps, n, mu1, mu2, sigma, rho)
par(mfrow = c(1, 2))
adam.qqplot(p_values, qunif)
hist(p_values)
quantile(p_values, c(0.01, 0.05))
@

In this case $\rho = 0.1$, which is still a relatively low correlation among random variables. Then the QQ-plot shows that the distribution of resulting p-values is very close to uniform. However, the true 0.01, 0.05 data quantiles are slightly larger than 0.01 and 0.05, which suggests that using 0.01 and 0.05 as cut values is conservative for this kind of scenario.

\problem
\subproblem
\proof
\begin{equation*}
\begin{aligned}
    l(x_{i}|\mu) &= \log L(x_{i}|\mu) = -\log\mu - \frac{x}{\mu}\\
    \Rightarrow l(x|\mu) &= \sum_{i = 1}^{n}{l(x_{i}|\mu)} = -n\log\mu - n\frac{\bar{x}}{\mu}
\end{aligned}
\end{equation*}
To maximize the log likelihood, we set its derivative to be 0:
\begin{equation*}
\begin{aligned}
    & \frac{\partial}{\partial \mu} l(x|\mu) = 0\\
    \Rightarrow & - \frac{1}{\mu} + \frac{\bar{x}}{\mu^2} = 0\\
    \Rightarrow & \hat{\mu} = \bar{x}
\end{aligned}
\end{equation*}
Q.E.D.

\subproblem
\begin{equation*}
\begin{aligned}
    & & L(a) &= \E\{(a\bar{x} - \mu)^2\} \\
    &\Rightarrow & L(a) &= \E\{(a(\bar{x} - E(\bar{x})) + a \E(\bar{x}) - \mu)^2\} \\
    &\Rightarrow & L(a) &= \E\{a^2(\bar{x} - E(\bar{x}))^2\} + \E\{(a\E(\bar{x}) - mu)^2 \} \\
    &\Rightarrow & L(a) &= a^2 \Var(\bar{x}) + a^2 \mu^2 - 2a \mu^2 + \mu^2\\
    & \Rightarrow & L(a) &= a^2 \frac{\mu^2}{n} + a^2 \mu^2 - 2a \mu^2 + \mu^2
\end{aligned}
\end{equation*}

Then set 
\begin{equation*}
\begin{aligned}
    & & &\frac{\partial}{\partial a}L(a) = 0\\
    &\Rightarrow& &2a\frac{\mu^2}{n} + 2a\mu^2 - 2\mu^2 = 0\\
    &\Rightarrow& &\hat{a} = \frac{\mu^2}{\frac{\mu^2}{n} + \mu^2} = \frac{n}{n + 1}
\end{aligned}
\end{equation*}

\subproblem
\begin{equation*}
\begin{aligned}
    \E\{(\bar{x} - \mu)^2\} &= \Var(\bar{x}) = \frac{\mu^2}{n} \\
    \E\{(a\bar{x} - \mu)^2\} &= a^2 \Var(\bar{x}) + (a\mu - \mu)^2 = \frac{1}{n + 1}\mu^2
\end{aligned}
\end{equation*}
The shrinkage estimator has the smaller mean-squared error.

\subproblem
In this problem we will first draw sample from the exponential distribution, and then calculate the simulated mean square errors for the two estimators: maximum likelihood estimator and the shrinkage estimator. We will replicate this procedure in several different scenarios, and then compare our simulated result with the result derived from the formula.\newline

<<p3.d>>=
#' simulate the mean square errors for likelihood estimator and shrinkage 
#' estimator for the mean of a Exponential distribution
#'
#' @param reps number of replications for this simulation
#' @param n sample size
#' @param mu mean of the Exponential distribution
#'
#' @return a vector containing simulated mean square errors for the two estimators
#' (likelihood, shrinkage)
sim_diff_lkh_shk = function(reps, n, mu) {
    x = rexp(reps * n, 1 / mu)
    x = matrix(x, reps, n)
    a = n / (n + 1)
    erros = apply(x, 1, function(x, mu) {
        c((mean(x) - mu) ^ 2, (a * mean(x) - mu) ^ 2)
    }, mu)
    apply(erros, 1, mean)
}

n_vec = c(5, 10, 50)
mu_vec = c(0.5, 1, 10)
reps = 1000
result = matrix(0, length(n_vec) * length(mu_vec), 6)
colnames(result) = c("n", "mu", "sim_lkh_err", "sim_shk_est",
                     "true_lkh_err", "true_shk_est")
k = 1
for (n in n_vec)
    for (mu in mu_vec) {
        result[k, 1] = n
        result[k, 2] = mu
        result[k, c(3, 4)] = sim_diff_lkh_shk(reps, n, mu)
        result[k, 5] = mu ^ 2 / n
        result[k, 6] = mu ^ 2 / (n + 1)
        k = k + 1
    }
round(result, 3)
@

From the resulting table we could see that the simulated estimates are very close the results derived in part 3c.

\end{document}